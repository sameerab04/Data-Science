{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal\n",
    "The goal of this project is to expose you with a real data science problem, looking at the end-to-end pipeline. \n",
    "\n",
    "### The Following Notebook will accomplish:\n",
    "\n",
    "* Access historical bike rental data for 2019 from HealthyRidePGH and summarize the rental data  \n",
    "* Create graphs to show the popularity of the different rental stations, given filter conditions  \n",
    "* Create graphs to show the rebalancing issue  \n",
    "* Cluster the data to group similar stations together, using a variety of clustering functions and visualize the results of the clustering.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.ioff()\n",
    "import pandas as pd\n",
    "from sklearn import cluster\n",
    "from scipy.spatial.distance import euclidean\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of interactive display in Jupyter, we will enable matplotlib inline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Access historical bike rental data for 2019 from HealthyRidePGH and summarize the rental dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# combining 2019 quarters into one dataframe \n",
    "q1 = pd.read_csv('HealthyRideRentals2019-Q1.csv')\n",
    "q2 = pd.read_csv('HealthyRideRentals2019-Q2.csv')\n",
    "q3 = pd.read_csv('HealthyRideRentals2019-Q3.csv')\n",
    "list = []\n",
    "list.append(q1)\n",
    "list.append(q2)\n",
    "list.append(q3)\n",
    "df = pd.concat(list)\n",
    "month = df.copy()\n",
    "day = df.copy()\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summarizing historical bike rental data for 2019 from HealthyRidePGH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "day['Starttime'] = pd.to_datetime(df['Starttime']).dt.date\n",
    "day['Stoptime'] = pd.to_datetime(df['Stoptime']).dt.date\n",
    "\n",
    "fromCNT = day.groupby(['Starttime', 'From station id']).size().reset_index(name = \"fromCNT\")\n",
    "toCNT = day.groupby(['Stoptime', 'To station id']).size().reset_index(name = \"toCNT\")\n",
    "\n",
    "fromCNT.rename(columns = {'Starttime':'Date'}, inplace = True)\n",
    "fromCNT.rename(columns = {'From station id':'Station id'}, inplace = True)\n",
    "toCNT.rename(columns = {'Stoptime':'Date'}, inplace = True)\n",
    "toCNT.rename(columns = {'To station id':'Station id'}, inplace = True)\n",
    "\n",
    "daily_breakdown = pd.merge(fromCNT, toCNT, how = \"inner\", on = [\"Date\", \"Station id\"])\n",
    "daily_breakdown['rebalCNT'] = daily_breakdown['fromCNT'] - daily_breakdown['toCNT']\n",
    "\n",
    "daily_breakdown['rebalCNT'] = daily_breakdown['rebalCNT'].abs()\n",
    "#daily_breakdown.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "month['Starttime'] = pd.to_datetime(df['Starttime']).dt.month\n",
    "month['Stoptime'] = pd.to_datetime(df['Stoptime']).dt.month\n",
    "\n",
    "fromCNT_month = month.groupby(['Starttime', 'From station id']).size().reset_index(name = \"fromCNT\")\n",
    "toCNT_month = month.groupby(['Stoptime', 'To station id']).size().reset_index(name = \"toCNT\")\n",
    "\n",
    "fromCNT_month.rename(columns = {'Starttime':'Month'}, inplace = True)\n",
    "fromCNT_month.rename(columns = {'From station id':'Station id'}, inplace = True)\n",
    "toCNT_month.rename(columns = {'Stoptime':'Month'}, inplace = True)\n",
    "toCNT_month.rename(columns = {'To station id':'Station id'}, inplace = True)\n",
    "\n",
    "monthly_breakdown = pd.merge(fromCNT_month, toCNT_month, how = \"inner\", on = [\"Month\", \"Station id\"])\n",
    "monthly_breakdown['rebalCNT'] = monthly_breakdown['fromCNT'] - monthly_breakdown['toCNT']\n",
    "monthly_breakdown['rebalCNT'] = monthly_breakdown['rebalCNT'].abs()\n",
    "#monthly_breakdown.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Create graphs to show the popularity of the different rental stations, given filter conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_month = 4\n",
    "filter_stationID = 1046\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IoffContext at 0x7ff72a49cb80>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month_filter = monthly_breakdown[monthly_breakdown['Month'] == filter_month]\n",
    "month_filter = month_filter.sort_values(by = ['fromCNT'], ascending = False)\n",
    "month_filter = month_filter[:25]\n",
    "plt.ioff()\n",
    "fig = plt.bar(range(len(month_filter['Station id'])), month_filter['fromCNT'])\n",
    "plt.xticks(range(len(month_filter['Station id'])), month_filter['Station id'], rotation = 90)\n",
    "plt.xlabel('Station id')\n",
    "plt.ylabel('fromCNT')\n",
    "plt.title(\"Most popular stations for month \" + str (filter_month))\n",
    "plt.ioff()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IoffContext at 0x7ff72e75d490>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_breakdown['Month'] = pd.DatetimeIndex(daily_breakdown['Date']).month\n",
    "daily_breakdown['Day'] = pd.DatetimeIndex(daily_breakdown['Date']).day\n",
    "\n",
    "month_filter = daily_breakdown[daily_breakdown['Month'] == filter_month]\n",
    "sid = month_filter[month_filter['Station id'] == filter_stationID]\n",
    "sid = sid.sort_values(by = ['fromCNT'], ascending = False)\n",
    "plt.ioff()\n",
    "fig = plt.bar(range(len(sid['Day'])), sid['fromCNT'])\n",
    "plt.xticks(range(len(sid['Day'])), sid['Day'])\n",
    "plt.xlabel(\"Days of month \" + str(filter_month))\n",
    "plt.ylabel(\"fromCNT\")\n",
    "plt.title(\"Most popular days of month \" + str(filter_month) + \" for station \" + str(filter_stationID))\n",
    "plt.ioff()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IoffContext at 0x7ff72b71f7c0>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Month'] = pd.DatetimeIndex(df['Starttime']).month\n",
    "df['Hour'] = pd.DatetimeIndex(df['Starttime']).hour\n",
    "month_filter = df[df['Month'] == filter_month]\n",
    "\n",
    "hours = month_filter.groupby(['Hour']).size().reset_index(name = \"fromCNT\")\n",
    "hours = hours.sort_values(by = ['fromCNT'], ascending = False)\n",
    "plt.ioff()\n",
    "fig = plt.bar(range(len(hours['Hour'])), hours['fromCNT'])\n",
    "plt.xticks(range(len(hours['Hour'])), hours['Hour'])\n",
    "plt.xlabel(\"Hours of the day in month \" + str(filter_month))\n",
    "plt.ylabel(\"fromCNT\")\n",
    "plt.title(\"Most popular hours of month \" + str(filter_month) + \" for all stations\" )\n",
    "plt.ioff()\n",
    "#plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IoffContext at 0x7ff72bd9f4f0>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalBikes = month.groupby(['Starttime', 'Bikeid']).size().reset_index(name = \"num_rented\")\n",
    "totalBikes.rename(columns = {'Starttime': 'Month'}, inplace = True)\n",
    "month_filter = totalBikes[totalBikes['Month'] == filter_month]\n",
    "month_filter = month_filter.sort_values(by = ['num_rented'], ascending = False)\n",
    "month_filter = month_filter[:25]\n",
    "plt.ioff()\n",
    "fig = plt.bar(range(len(month_filter['Bikeid'])), month_filter['num_rented'])\n",
    "plt.xticks(range(len(month_filter['Bikeid'])), month_filter['Bikeid'], rotation = 90)\n",
    "plt.xlabel(\"Bike Id\")\n",
    "plt.ylabel(\"Number of times bikes were rented\")\n",
    "plt.title(\"Top 25 most popular bikes rented during month \" + str(filter_month))\n",
    "plt.ioff()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Create graphs to show the rebalancing issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IoffContext at 0x7ff72b9b44c0>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month_filter = monthly_breakdown[monthly_breakdown['Month'] == filter_month]\n",
    "month_filter = month_filter.sort_values(by = ['rebalCNT'], ascending = False)\n",
    "month_filter = month_filter[:25]\n",
    "plt.ioff()\n",
    "fig = plt.bar(range(len(month_filter['Station id'])), month_filter['rebalCNT'])\n",
    "plt.xticks(range(len(month_filter['Station id'])), month_filter['Station id'], rotation = 90)\n",
    "plt.xlabel(\"Station id \")\n",
    "plt.ylabel(\"rebalCNT\")\n",
    "plt.title(\"Most popular stations (rebalCNT) for month \" + str(filter_month))\n",
    "plt.ioff()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IoffContext at 0x7ff72f039a90>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sid = sid.sort_values(by = ['rebalCNT'], ascending = False)\n",
    "plt.ioff()\n",
    "fig = plt.bar(range(len(sid['Day'])), sid['rebalCNT'])\n",
    "plt.xticks(range(len(sid['Day'])), sid['Day'])\n",
    "plt.xlabel(\"Days of month \" + str(filter_month))\n",
    "plt.ylabel(\"rebalCNT\")\n",
    "plt.title(\"Most popular days of month \" + str(filter_month) + \" for station \" + str(filter_stationID))\n",
    "plt.ioff()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Cluster the data to group similar stations together, using a variety of clustering functions and visualize the results of the clustering.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster7 = monthly_breakdown[monthly_breakdown['Month'] == 7]\n",
    "cluster7.rename(columns = {'fromCNT':'fromCNT_7'}, inplace = True)\n",
    "cluster7.rename(columns = {'rebalCNT':'rebalCNT_7'}, inplace = True)\n",
    "cluster7.drop(columns = {'Month', 'toCNT'}, inplace = True)\n",
    "\n",
    "cluster8 = monthly_breakdown[monthly_breakdown['Month'] == 8]\n",
    "cluster8.rename(columns = {'fromCNT':'fromCNT_8'}, inplace = True)\n",
    "cluster8.rename(columns = {'rebalCNT':'rebalCNT_8'}, inplace = True)\n",
    "cluster8.drop(columns = {'Month', 'toCNT'}, inplace = True)\n",
    "\n",
    "cluster9 = monthly_breakdown[monthly_breakdown['Month'] == 9]\n",
    "cluster9.rename(columns = {'fromCNT':'fromCNT_9'}, inplace = True)\n",
    "cluster9.rename(columns = {'rebalCNT':'rebalCNT_9'}, inplace = True)\n",
    "cluster9.drop(columns = {'Month', 'toCNT'}, inplace = True)\n",
    "\n",
    "q3_cluster = cluster7.merge(cluster8,on='Station id').merge(cluster9,on='Station id')\n",
    "#q3_cluster.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-Means clustering \n",
    "\n",
    "def generate_kmeans_cluster(n_clusters, cluster_name):\n",
    "    k_means = cluster.KMeans(n_clusters = n_clusters, init = 'k-means++', random_state = 5000)\n",
    "    k_means_cluster = k_means.fit(q3_cluster[[ 'fromCNT_7', 'rebalCNT_7', 'fromCNT_8', 'rebalCNT_8', 'fromCNT_9', 'rebalCNT_9']])\n",
    "    labels = k_means_cluster.labels_\n",
    "    q3_cluster[cluster_name] = labels\n",
    "    \n",
    "generate_kmeans_cluster(2, 'ClusterID_one')\n",
    "generate_kmeans_cluster(3, 'ClusterID_two')\n",
    "generate_kmeans_cluster(4, 'ClusterID_three')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DBScan clustering \n",
    "\n",
    "def dbscan(eps, samples, cluster_name):\n",
    "\n",
    "    dbscan = cluster.DBSCAN(eps=eps, min_samples= samples, metric = 'euclidean', algorithm = 'auto', leaf_size = 30, p= None, n_jobs = 1)\n",
    "    dbscan_one = dbscan.fit(q3_cluster[[ 'fromCNT_7', 'rebalCNT_7', 'fromCNT_8', 'rebalCNT_8', 'fromCNT_9', 'rebalCNT_9']])\n",
    "    labels = dbscan_one.labels_\n",
    "    q3_cluster[cluster_name] = labels\n",
    "    \n",
    "dbscan(20,2,'db_clusterID_one')\n",
    "dbscan(20,2,'db_clusterID_two')\n",
    "dbscan(20,2,'db_clusterID_three')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(cluster_name, title):\n",
    "    kmeans = q3_cluster[cluster_name].value_counts().reset_index(name = \"Num stations\")\n",
    "    plt.ioff()\n",
    "    fig = plt.bar(range(len(kmeans)), kmeans['Num stations'])\n",
    "    plt.xticks(range(len(kmeans['index'])), kmeans['index'])\n",
    "    plt.xlabel(\"Cluster ID\")\n",
    "    plt.ylabel(\"Number of Stations\")\n",
    "    plt.title(title)\n",
    "    #plt.show()\n",
    "\n",
    "create_graph('ClusterID_one','K-Means with two clusters')\n",
    "create_graph('ClusterID_two','K-Means with three clusters')\n",
    "create_graph('ClusterID_three','K-Means with four clusters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def create_db_graph(cluster_name, title):\n",
    "    db = q3_cluster[cluster_name].value_counts().reset_index(name = \"Num stations\")\n",
    "    plt.ioff()\n",
    "    fig = plt.bar(range(len(db)), db['Num stations'])\n",
    "    plt.xticks(range(len(db['index'])), db['index'])\n",
    "    plt.xlabel(\"Cluster ID\")\n",
    "    plt.ylabel(\"Number of Stations\")\n",
    "    plt.title(title)\n",
    "    #plt.show()\n",
    "create_db_graph('db_clusterID_one', 'DBScan (eps = 20, min_sample = 2)')\n",
    "create_db_graph('db_clusterID_two', 'DBScan (eps = 20, min_sample = 3)')\n",
    "create_db_graph('db_clusterID_three', 'DBScan (eps = 20, min_sample = 4)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the k-means clustering, I chose to run the clustering with 2,3,and 4 clusters. I chose these cluster numbers because I wanted to see what would happen as the number of clusters increased and how that affects the overall effectiveness of the algorithms. From the output of the three clustering algorithms, I believe that the best K value of the three, is three clusters. This is because with two clusters, some data points that should be apart of their own cluster are forced to be grouped with the two clusters, even if they do not match. Four clusters, overly divides the clusters. With regard to if the K-Means or DBscan is better, I would argue that the K-means is better because all three simulations of the DB-scan contains noise points. These points are not visited, and therefore not considered. This can lead to inaccurate results. \n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
